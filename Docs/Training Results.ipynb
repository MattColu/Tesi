{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_name = \"matteo_*_cumulative*\"\n",
    "#run_name = \"matteo_?laps*\"\n",
    "#run_name = \"rl_trained*\"\n",
    "#run_name = \"matte_8laps_aio\"\n",
    "#run_name = \"matteo_3laps\"\n",
    "#run_name = \"matteo_2_cumulative0124\"\n",
    "result_path = \"../Training/results\"\n",
    "training_step_length = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plotdict(evallist: list, split_length: int = 20) -> dict:\n",
    "    plotdict = {}\n",
    "    for eval in evallist:\n",
    "        with open(eval) as e:\n",
    "            tdict = {}\n",
    "            for line in e.readlines():\n",
    "                jdict = json.loads(line)\n",
    "                if jdict[\"splitLength\"] == split_length:\n",
    "                    trackName = jdict[\"fileName\"].split('-')[0]\n",
    "                    if trackName not in tdict:\n",
    "                        tdict[trackName] = []\n",
    "                    tdict[trackName].append(jdict[\"result\"])\n",
    "        for key in tdict.keys():\n",
    "            tdict[key] = [sum(tdict[key])/len(tdict[key])]\n",
    "        \n",
    "        for key, value in tdict.items():\n",
    "            if key in plotdict.keys():\n",
    "                plotdict[key] += value\n",
    "            else:\n",
    "                plotdict[key] = value\n",
    "    return plotdict\n",
    "\n",
    "def plot_dict(plotdict: dict, color_dict: dict, xrange = None, artist = None):\n",
    "    if artist == None:\n",
    "        artist = plt.subplot()\n",
    "    if all(len(v) == 1 for v in plotdict.values()):\n",
    "        artist.bar(list(plotdict.keys()), [v[0] for v in plotdict.values()], color=[color_dict[k] for k in plotdict.keys()])\n",
    "    else:\n",
    "        for track in plotdict.keys():\n",
    "            if xrange is None:\n",
    "                artist.plot(range(training_step_length, (len(plotdict[track]) + 1) * training_step_length, training_step_length), plotdict[track], label=track, color=color_dict[track])\n",
    "            else:\n",
    "                artist.plot(xrange, plotdict[track], label=track, color=color_dict[track])\n",
    "        artist.legend()\n",
    "    artist.set_ylim(0, 1)\n",
    "    artist.set_title(\"Evaluation\")\n",
    "\n",
    "def extract_tfevents(path: str, tag: str = \"Policy/Gail Reward\"):\n",
    "    plotlist = []\n",
    "    tffile = glob.glob(f\"{path}/Kart/events*\")[0]\n",
    "    for e in summary_iterator(tffile):\n",
    "        for v in e.summary.value:\n",
    "            if v.tag == tag:\n",
    "                plotlist.append(v.simple_value)\n",
    "    return plotlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPER EVALUATION-O-MATIC 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list = [f\"Track{n}\" for n in range(5)]\n",
    "#track_list = [\"Square\", \"8\", \"Monza\", \"Spa\", \"Twisty\"]\n",
    "color_list = [f\"C{n}\" for n in range(5)]\n",
    "color_dict = {track_list[n]: color_list[n] for n in range(5)}\n",
    "\n",
    "tag = \"Policy/Gail Reward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAIL Reward / Evaluation, N per Lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"matteo_3laps\"\n",
    "split_length = 20\n",
    "\n",
    "for trackN in range(5):\n",
    "    evallist = []\n",
    "    tflist = []\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    \n",
    "    for run in glob.glob(f\"{result_path}/{run_name}_Track{trackN}_*\"):\n",
    "        evallist.append(run + \"/\" + \"evaluations.jsonl\")\n",
    "        tflist += extract_tfevents(run, tag)\n",
    "   \n",
    "    plot_dict(generate_plotdict(evallist, split_length), color_dict, artist = ax2)\n",
    "    ax1.plot(np.linspace(1e5, 1e6, len(tflist)), tflist, label= track_list[trackN], color=color_list[trackN])\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(0, 1200)\n",
    "    ax1.set_title(tag)\n",
    "    fig.suptitle(run_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation / Evaluation, N per Lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"matteo_3laps\"\n",
    "\n",
    "for trackN in range(5):\n",
    "    evallist = []\n",
    "    tflist = []\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    \n",
    "    for run in glob.glob(f\"{result_path}/{run_name}_Track{trackN}_*\"):\n",
    "        evallist.append(run + \"/\" + \"evaluations.jsonl\")\n",
    "   \n",
    "    plot_dict(generate_plotdict(evallist, 20), color_dict, artist = ax1)\n",
    "    plot_dict(generate_plotdict(evallist, 40), color_dict, artist = ax2)\n",
    "    fig.suptitle(run_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAIL Reward / Evaluation, Cumulative 0124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"matteo_2_cumulative0124\"\n",
    "\n",
    "evallist = []\n",
    "ax1 = plt.subplot(223)\n",
    "ax2 = plt.subplot(224)\n",
    "\n",
    "for trackN in range(4):\n",
    "    trackName = track_list[[0, 1, 2, 4][trackN]]\n",
    "    tflist = []\n",
    "\n",
    "    axn = plt.subplot(2, 4, trackN + 1)\n",
    "\n",
    "    for run in glob.glob(f\"{result_path}/{run_name}_{trackN}\"):\n",
    "        evallist.append(run + \"/\" + \"evaluations.jsonl\")\n",
    "        tflist += extract_tfevents(run, tag)    \n",
    "    axn.plot(np.linspace(1e5, 1e6, len(tflist)), tflist, label=trackName, color=color_dict[trackName])\n",
    "    axn.legend()\n",
    "    axn.set_ylim(0, 1200)\n",
    "\n",
    "plotdict = generate_plotdict(evallist)\n",
    "ax1.bar(range(4), plotdict[\"Track3\"], label=\"Track3\", color=color_dict[\"Track3\"])\n",
    "ax2.bar(range(4), plotdict[\"Track3\"], label=\"Track3\", color=color_dict[\"Track3\"])\n",
    "ax1.set_ylim(0, 1)\n",
    "ax2.set_ylim(0.55, 0.75)\n",
    "ax1.legend()\n",
    "\n",
    "ax1.indicate_inset_zoom(ax2)\n",
    "plt.suptitle(run_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation / Evaluation, Cumulative 0124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"matteo_2_cumulative0124\"\n",
    "\n",
    "evallist = []\n",
    "\n",
    "for trackN in range(4):\n",
    "    for run in glob.glob(f\"{result_path}/{run_name}_{trackN}\"):\n",
    "        evallist.append(run + \"/\" + \"evaluations.jsonl\")\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "\n",
    "plotdict1 = generate_plotdict(evallist, 20)\n",
    "plotdict2 = generate_plotdict(evallist, 40)\n",
    "\n",
    "params1 = {\"x\": range(4), \"height\": plotdict1[\"Track3\"], \"label\": \"Track3\", \"color\": color_dict[\"Track3\"]}\n",
    "params2 = {\"x\": range(4), \"height\": plotdict2[\"Track3\"], \"label\": \"Track3\", \"color\": color_dict[\"Track3\"]}\n",
    "\n",
    "ax1.bar(**params1)\n",
    "ax2.bar(**params2)\n",
    "ax3.bar(**params1)\n",
    "ax4.bar(**params2)\n",
    "\n",
    "ax1.set_ylim(0, 1)\n",
    "ax3.set_ylim(0.55, 0.75)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax4.set_ylim(0.30, 0.50)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.indicate_inset_zoom(ax3)\n",
    "ax2.indicate_inset_zoom(ax4)\n",
    "\n",
    "plt.suptitle(run_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Plot\n",
    "\n",
    "The following cell loads all `evaluation<...>.json` files and plots their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"matteo_?laps*\"\n",
    "xrange = np.linspace(3, 9, 60)\n",
    "\n",
    "#run_name = \"matteo_*_cumulative*\"\n",
    "#xrange = np.linspace(2, 11, 36)\n",
    "\n",
    "split_length = 20\n",
    "\n",
    "evallist = glob.glob(f\"{result_path}/{run_name}/evaluations.jsonl\")\n",
    "\n",
    "plotdict = generate_plotdict(evallist, split_length)\n",
    "\n",
    "plot_dict(plotdict, color_dict, xrange)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation Plot\n",
    "\n",
    "The following cell takes the last elements for each `run_name..._N` series of runs and plots their `evaluations.jsonl` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"matteo_?laps*\"\n",
    "xrange = range(3,9)\n",
    "\n",
    "#run_name = \"matteo_*_cumulative*\"\n",
    "#xrange = range(2,11)\n",
    "\n",
    "split_length = 20\n",
    "\n",
    "all_evaluations = glob.glob(f\"{result_path}/{run_name}/evaluations.jsonl\")\n",
    "\n",
    "all_runs = list(map(lambda evaljson: os.path.dirname(evaljson), all_evaluations))\n",
    "highest_run_number = max(map(lambda run: run.split('_')[-1], all_runs))\n",
    "all_last_runs = list(filter(lambda run: run.endswith(highest_run_number), all_runs))\n",
    "evallist = [f\"{run}/evaluations.jsonl\" for run in all_last_runs]\n",
    "\n",
    "plotdict = generate_plotdict(evallist, split_length)\n",
    "\n",
    "\n",
    "plot_dict(plotdict, color_dict, xrange)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
